{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MTH8408 : Méthodes d'optimisation et contrôle optimal\n",
    " ## Laboratoire 4: Optimisation sans contraintes et méthodes itératives\n",
    "Tangi Migot et Paul Raynaud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling ADNLPModels [54578032-b7ea-4c30-94aa-7cbd1cce6c9a]\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra, Krylov, NLPModels, Printf, Logging, SolverCore, Test, ADNLPModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADNLSModel - Nonlinear least-squares model with automatic differentiation backend ADModelBackend{\n",
       "  ForwardDiffADGradient,\n",
       "  ForwardDiffADHvprod,\n",
       "  EmptyADbackend,\n",
       "  EmptyADbackend,\n",
       "  EmptyADbackend,\n",
       "  ForwardDiffADHessian,\n",
       "  EmptyADbackend,\n",
       "}\n",
       "  Problem name: Generic\n",
       "   All variables: ████████████████████ 2      All constraints: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0        All residuals: ████████████████████ 2     \n",
       "            free: ████████████████████ 2                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            nonlinear: ████████████████████ 2     \n",
       "           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 nnzj: (  0.00% sparsity)   4     \n",
       "         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 nnzh: (  0.00% sparsity)   3     \n",
       "           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "            nnzh: (  0.00% sparsity)   3               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                    nonlinear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                         nnzj: (------% sparsity)         \n",
       "\n",
       "  Counters:\n",
       "             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "    jac_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0      jtprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "   hess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jhess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       hprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test problem:\n",
    "FH(x) = [x[2]+x[1].^2-11, x[1]+x[2].^2-7]\n",
    "x0H = [10., 20.]\n",
    "###########################\n",
    "#Utilise FH et x0H pour créer un ADNLSModel\n",
    "himmelblau_nls = ADNLPModels.ADNLSModel(FH, x0H, 2)\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1: Gauss-Newton\n",
    "\n",
    "Dans cet exercice, on complète une implémentation de la méthode Gauss-Newton avec région de confiance (paramétrée par $\\Delta$) discutée en cours.\n",
    "\n",
    "Il faut compléter les morceaux:\n",
    "- utiliser les fonctions des NLSModels pour obtenir F et sa jacobienne (ici on utilise pas la jacobienne mais juste le produit jacobienne-vecteur).\n",
    "Parcourez la documentation de NLPModels pour déterminer la fonction adéquat, indice les fonctions pour les NLSModels indiquent des `nls` au lieu de `nlp` dans la documentation.\n",
    "- Utiliser la fonction `lsmr` du package `Krylov.jl` pour résoudre le système linéaire avec une contrainte de `radius`. Lisez la [documentation de `lsmr`](https://jso.dev/Krylov.jl/stable/solvers/ls/#LSMR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gauss_newton (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gauss_newton(nlp      :: AbstractNLSModel, \n",
    "                      x        :: AbstractVector, \n",
    "                      ϵ        :: AbstractFloat;\n",
    "                      η₁       :: AbstractFloat = 1e-3, \n",
    "                      η₂       :: AbstractFloat = 0.66, \n",
    "                      σ₁       :: AbstractFloat = 0.25, \n",
    "                      σ₂       :: AbstractFloat = 2.0,\n",
    "                      max_eval :: Int = 1_000, \n",
    "                      max_time :: AbstractFloat = 60.,\n",
    "                      max_iter :: Int = typemax(Int64)\n",
    "                      )\n",
    "    ######################################################\n",
    "    Fx = NLPModels.residual(himmelblau_nls, x)\n",
    "    Jx = NLPModels.jac_residual(himmelblau_nls, x)\n",
    "    ######################################################\n",
    "    normFx = norm(Fx)\n",
    "\n",
    "    Δ = 1.\n",
    "\n",
    "    iter = 0    \n",
    "\n",
    "    el_time = 0.0\n",
    "    tired   = neval_residual(nlp) > max_eval || el_time > max_time\n",
    "    status  = :unknown\n",
    "\n",
    "    start_time = time()\n",
    "    too_small  = false\n",
    "    normdual   = norm(Jx' * Fx)\n",
    "    optimal    = min(normFx, normdual) ≤ ϵ\n",
    "\n",
    "    @info log_header([:iter, :nf, :primal, :status, :nd, :Δ],\n",
    "    [Int, Int, Float64, String, Float64, Float64],\n",
    "    hdr_override=Dict(:nf => \"#F\", :primal => \"‖F(x)‖\", :nd => \"‖d‖\"))\n",
    "\n",
    "    while !(optimal || tired || too_small)\n",
    "\n",
    "        #################################\n",
    "        #Compute a direction satisfying the trust-region constraint\n",
    "        (d, stats)  = lsmr(-Jx, Fx, radius = Δ)\n",
    "        #################################\n",
    "      \n",
    "        too_small = norm(d) < 1e-15\n",
    "        if too_small #the direction is too small\n",
    "            status = :too_small\n",
    "        else\n",
    "            xp      = x + d\n",
    "            ###########################\n",
    "            Fxp     = NLPModels.residual(himmelblau_nls, xp)\n",
    "            ###########################\n",
    "            normFxp = norm(Fxp)\n",
    "\n",
    "            Pred = 0.5 * (normFx^2 - norm(Jx * d + Fx)^2)\n",
    "            Ared = 0.5 * (normFx^2 - normFxp^2)\n",
    "\n",
    "            if Ared/Pred < η₁\n",
    "                Δ = max(1e-8, Δ * σ₁)\n",
    "                status = :reduce_Δ\n",
    "            else #success\n",
    "                x  = xp\n",
    "                ###########################\n",
    "                Jx = NLPModels.jac_residual(himmelblau_nls, x)\n",
    "                ###########################\n",
    "                Fx = Fxp\n",
    "                normFx = normFxp\n",
    "                status = :success\n",
    "                if Ared/Pred > η₂ && norm(d) >= 0.99 * Δ\n",
    "                    Δ *= σ₂\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        @info log_row(Any[iter, neval_residual(nlp), normFx, status, norm(d), Δ])\n",
    "\n",
    "        el_time      = time() - start_time\n",
    "        iter   += 1\n",
    "\n",
    "        many_evals   = neval_residual(nlp) > max_eval\n",
    "        iter_limit   = iter > max_iter\n",
    "        tired        = many_evals || el_time > max_time || iter_limit\n",
    "        normdual     = norm(Jx' * Fx)\n",
    "        optimal      = min(normFx, normdual) ≤ ϵ\n",
    "    end\n",
    "\n",
    "    status = if optimal \n",
    "        :first_order\n",
    "    elseif tired\n",
    "        if neval_residual(nlp) > max_eval\n",
    "            :max_eval\n",
    "        elseif el_time > max_time\n",
    "            :max_time\n",
    "        elseif iter > max_iter\n",
    "            :max_iter\n",
    "        else\n",
    "            :unknown_tired\n",
    "        end\n",
    "    elseif too_small\n",
    "        :stalled\n",
    "    else\n",
    "        :unknown\n",
    "    end\n",
    "\n",
    "    return GenericExecutionStats(nlp; status, solution = x,\n",
    "                                 objective = normFx^2 / 2,\n",
    "                                 dual_feas = normdual,\n",
    "                                 iter = iter, \n",
    "                                 elapsed_time = el_time)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  iter      #F    ‖F(x)‖           status       ‖d‖         Δ  \n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     0       2   3.8e+02          success   1.0e+00   2.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     1       3   3.1e+02          success   2.0e+00   4.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     2       4   1.9e+02          success   4.0e+00   8.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     3       5   4.5e+01          success   7.7e+00   8.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     4       6   9.5e+00          success   3.4e+00   8.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     5       7   1.6e+00          success   1.3e+00   8.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     6       8   1.2e-01          success   3.5e-01   8.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     7       9   8.8e-04          success   3.0e-02   8.0e+00\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m     8      10   5.3e-08          success   2.3e-04   8.0e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = gauss_newton(himmelblau_nls, himmelblau_nls.meta.x0, 1e-6)\n",
    "@test stats.status == :first_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: Méthode Levenberg-Marquard inexacte\n",
    "\n",
    "Dans cet exercice, on complète une implémentation de la méthode Levenberg-Marquardt. Pour compléter le code `lm_param` on va utiliser les fonctions suivantes:\n",
    "- `dsol` qui calcul la solution du système \n",
    "$\\min_x \\frac{1}{2}\\|J(x) d + F(x)\\| + \\lambda \\|x\\|^2$\n",
    "avec la fonction `lsqr` du package `Krylov.jl`.\n",
    "- `multi_sol` qui pour un entier nl donné et un $\\mu$ va résoudre le problème de dsol pour nl valeurs de $\\lambda$ (autour de la valeur $\\mu$). Par exemple, pour $\\mu=10^{-6}$ et $nl=3$, on prendra $\\lambda=10^{-7}, 10^{-6},10^{-5}$.\n",
    "Parmis les `nl` directions calculées, on retourne celle qui donne la plus petite valeur de $\\|F(x+d)\\|^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsol (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function dsol(Fx, Jx, λ)\n",
    "    (d, stats) = lsqr(-Jx, Fx, λ)\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "multi_sol (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function multi_sol(nlp, x, Fx, Jx, λ, τ; nl = 3)\n",
    "    λ=zeros(nl)\n",
    "    if nl % 2 == 0  \n",
    "        for i=1:nl\n",
    "            λ[i] = τ/(10^(nl/2 - i + 2))\n",
    "        end\n",
    "    else  \n",
    "        for i=1:nl\n",
    "            λ[i] = τ/(10^((nl-1)/2 - i + 1))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    for valeur in λ\n",
    "        print(valeur)\n",
    "        d = dsol(Fx, Jx, valeur) \n",
    "        x_new = x + d\n",
    "        norm_sq = norm(Fx(x_new))^2 \n",
    "        if norm_sq < min_norm_sq\n",
    "            min_norm_sq = norm_sq\n",
    "            best_d = d\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return best_d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lm_param (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lm_param(nlp      :: AbstractNLSModel, \n",
    "                  x        :: AbstractVector, \n",
    "                  ϵ        :: AbstractFloat;\n",
    "                  η₁       :: AbstractFloat = 1e-3, \n",
    "                  η₂       :: AbstractFloat = 0.66, \n",
    "                  σ₁       :: AbstractFloat = 10.0, \n",
    "                  σ₂       :: AbstractFloat = 0.5,\n",
    "                  max_eval :: Int = 10_000, \n",
    "                  max_time :: AbstractFloat = 60.,\n",
    "                  max_iter :: Int = typemax(Int64)\n",
    "                  )\n",
    "    ######################################################\n",
    "    Fx = NLPModels.residual(himmelblau_nls, x)\n",
    "    Jx = NLPModels.jac_residual(himmelblau_nls, x)\n",
    "    ######################################################\n",
    "    normFx   = norm(Fx)\n",
    "    normdual = norm(Jx' * Fx)\n",
    "\n",
    "    iter = 0    \n",
    "    λ = 0.0\n",
    "    λ₀ = 1e-6\n",
    "    η = 0.5\n",
    "    τ = η * normdual\n",
    "\n",
    "    el_time = 0.0\n",
    "    tired   = neval_residual(nlp) > max_eval || el_time > max_time\n",
    "    status  = :unknown\n",
    "\n",
    "    start_time = time()\n",
    "    too_small  = false\n",
    "    optimal    = min(normFx, normdual) ≤ ϵ\n",
    "\n",
    "    @info log_header([:iter, :nf, :primal, :status, :nd, :λ],\n",
    "    [Int, Int, Float64, String, Float64, Float64],\n",
    "    hdr_override=Dict(:nf => \"#F\", :primal => \"‖F(x)‖\", :nd => \"‖d‖\"))\n",
    "\n",
    "    while !(optimal || tired || too_small)\n",
    "\n",
    "        ###########################\n",
    "        # (d, stats)  = lsqr(Jx, -Fx, λ = λ, atol = τ)\n",
    "        d = multi_sol(nlp, x, Fx, Jx, λ, τ)\n",
    "        ###########################\n",
    "        \n",
    "        too_small = norm(d) < 1e-16\n",
    "        if too_small #the direction is too small\n",
    "            status = :too_small\n",
    "        else\n",
    "            xp      = x + d\n",
    "            ###########################\n",
    "            Fxp     = NLPModels.residual(himmelblau_nls, xp)\n",
    "            ###########################\n",
    "            normFxp = norm(Fxp)\n",
    "\n",
    "            Pred = 0.5 * (normFx^2 - norm(Jx * d + Fx)^2 - λ*norm(d)^2)\n",
    "            Ared = 0.5 * (normFx^2 - normFxp^2)\n",
    "\n",
    "            if Ared/Pred < η₁\n",
    "                λ = max(λ₀, σ₁ * λ)\n",
    "                status = :increase_λ\n",
    "            else #success\n",
    "                x  = xp\n",
    "                ###########################\n",
    "                Jx = NLPModels.jac_residual(himmelblau_nls, x)\n",
    "                ###########################\n",
    "                Fx = Fxp\n",
    "                normFx = normFxp\n",
    "                status = :success\n",
    "                if Ared/Pred > η₂\n",
    "                    λ = max(λ * σ₂, λ₀)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "        @info log_row(Any[iter, neval_residual(nlp), normFx, status, norm(d), λ])\n",
    "\n",
    "        el_time      = time() - start_time\n",
    "        iter        += 1\n",
    "        many_evals   = neval_residual(nlp) > max_eval\n",
    "        iter_limit   = iter > max_iter\n",
    "        tired        = many_evals || el_time > max_time || iter_limit\n",
    "        normdual     = norm(Jx' * Fx)\n",
    "        optimal      = min(normFx, normdual) ≤ ϵ\n",
    "\n",
    "        η = λ == 0.0 ? min(0.5, 1/iter, normdual) : min(0.5, 1/iter)\n",
    "        τ = η * normdual\n",
    "    end\n",
    "\n",
    "    status = if optimal \n",
    "        :first_order\n",
    "    elseif tired\n",
    "        if neval_residual(nlp) > max_eval\n",
    "            :max_eval\n",
    "        elseif el_time > max_time\n",
    "            :max_time\n",
    "        elseif iter > max_iter\n",
    "            :max_iter\n",
    "        else\n",
    "            :unknown_tired\n",
    "        end\n",
    "    elseif too_small\n",
    "        :stalled\n",
    "    else\n",
    "        :unknown\n",
    "    end\n",
    "\n",
    "    return GenericExecutionStats(nlp; status, solution = x,\n",
    "                                 objective = normFx^2 / 2,\n",
    "                                 dual_feas = normdual,\n",
    "                                 iter = iter, \n",
    "                                 elapsed_time = el_time)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821.663449959897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m  iter      #F    ‖F(x)‖           status       ‖d‖         λ  \n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching lsqr(::SparseArrays.SparseMatrixCSC{Float64, Int64}, ::Vector{Float64}, ::Float64)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  lsqr(::Any, ::AbstractVector{FC}; window, M, N, ldiv, sqd, λ, radius, etol, axtol, btol, conlim, atol, rtol, itmax, timemax, verbose, history, callback, iostream) where {T<:AbstractFloat, FC<:Union{Complex{T}, T}}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mKrylov\u001b[39m \u001b[90mC:\\Users\\Ulrizpascuit\\.julia\\packages\\Krylov\\pv2NF\\src\\\u001b[39m\u001b[90m\u001b[4mlsqr.jl:158\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching lsqr(::SparseArrays.SparseMatrixCSC{Float64, Int64}, ::Vector{Float64}, ::Float64)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  lsqr(::Any, ::AbstractVector{FC}; window, M, N, ldiv, sqd, λ, radius, etol, axtol, btol, conlim, atol, rtol, itmax, timemax, verbose, history, callback, iostream) where {T<:AbstractFloat, FC<:Union{Complex{T}, T}}\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[36mKrylov\u001b[39m \u001b[90mC:\\Users\\Ulrizpascuit\\.julia\\packages\\Krylov\\pv2NF\\src\\\u001b[39m\u001b[90m\u001b[4mlsqr.jl:158\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      " [1] dsol(Fx::Vector{Float64}, Jx::SparseArrays.SparseMatrixCSC{Float64, Int64}, λ::Float64)",
      "   @ Main .\\In[12]:2",
      " [2] multi_sol(nlp::ADNLSModel{Float64, Vector{Float64}, Vector{Int64}}, x::Vector{Float64}, Fx::Vector{Float64}, Jx::SparseArrays.SparseMatrixCSC{Float64, Int64}, λ::Float64, τ::Float64; nl::Int64)",
      "   @ Main .\\In[13]:15",
      " [3] multi_sol(nlp::ADNLSModel{Float64, Vector{Float64}, Vector{Int64}}, x::Vector{Float64}, Fx::Vector{Float64}, Jx::SparseArrays.SparseMatrixCSC{Float64, Int64}, λ::Float64, τ::Float64)",
      "   @ Main .\\In[13]:1",
      " [4] lm_param(nlp::ADNLSModel{Float64, Vector{Float64}, Vector{Int64}}, x::Vector{Float64}, ϵ::Float64; η₁::Float64, η₂::Float64, σ₁::Float64, σ₂::Float64, max_eval::Int64, max_time::Float64, max_iter::Int64)",
      "   @ Main .\\In[7]:41",
      " [5] lm_param(nlp::ADNLSModel{Float64, Vector{Float64}, Vector{Int64}}, x::Vector{Float64}, ϵ::Float64)",
      "   @ Main .\\In[7]:1",
      " [6] top-level scope",
      "   @ In[14]:1"
     ]
    }
   ],
   "source": [
    "stats = lm_param(himmelblau_nls, himmelblau_nls.meta.x0, 1e-6)\n",
    "@test stats.status == :first_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: Rocket Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les cellules ci-dessous nous introduisons un modèle de contrôle optimal (cf. https://en.wikipedia.org/wiki/Optimal_control ) pour le contrôle d'une fusée dont une version discrétisée a été modélisé avec JuMP:\n",
    "\n",
    "Le lien vers le tutoriel:\n",
    "https://nbviewer.jupyter.org/github/jump-dev/JuMPTutorials.jl/blob/master/notebook/modelling/rocket_control.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Ipopt\n",
    "\n",
    "# Create JuMP model, using Ipopt as the solver\n",
    "rocket = Model(optimizer_with_attributes(Ipopt.Optimizer, \"print_level\" => 0))\n",
    "\n",
    "# Constants\n",
    "# Note that all parameters in the model have been normalized\n",
    "# to be dimensionless. See the COPS3 paper for more info.\n",
    "h_0 = 1    # Initial height\n",
    "v_0 = 0    # Initial velocity\n",
    "m_0 = 1    # Initial mass\n",
    "g_0 = 1    # Gravity at the surface\n",
    "\n",
    "T_c = 3.5  # Used for thrust\n",
    "h_c = 500  # Used for drag\n",
    "v_c = 620  # Used for drag\n",
    "m_c = 0.6  # Fraction of initial mass left at end\n",
    "\n",
    "c     = 0.5 * sqrt(g_0 * h_0)  # Thrust-to-fuel mass\n",
    "m_f   = m_c * m_0            # Final mass\n",
    "D_c   = 0.5 * v_c * m_0 / g_0    # Drag scaling\n",
    "T_max = T_c * g_0 * m_0        # Maximum thrust\n",
    "\n",
    "n = 800   # Time steps\n",
    "\n",
    "@variables(rocket, begin\n",
    "    Δt ≥ 0, (start = 1/n) # Time step\n",
    "    # State variables\n",
    "    v[1:n] ≥ 0            # Velocity\n",
    "    h[1:n] ≥ h_0          # Height\n",
    "    m_f ≤ m[1:n] ≤ m_0    # Mass\n",
    "    # Control\n",
    "    0 ≤ T[1:n] ≤ T_max    # Thrust\n",
    "end)\n",
    "\n",
    "# Objective: maximize altitude at end of time of flight\n",
    "@objective(rocket, Max, h[n])\n",
    "\n",
    "# Initial conditions\n",
    "@constraints(rocket, begin\n",
    "    v[1] == v_0\n",
    "    h[1] == h_0\n",
    "    m[1] == m_0\n",
    "    m[n] == m_f\n",
    "end)\n",
    "\n",
    "# Forces\n",
    "# Drag(h,v) = Dc v^2 exp( -hc * (h - h0) / h0 )\n",
    "@NLexpression(rocket, drag[j = 1:n], D_c * (v[j]^2) * exp(-h_c * (h[j] - h_0) / h_0))\n",
    "# Grav(h)   = go * (h0 / h)^2\n",
    "@NLexpression(rocket, grav[j = 1:n], g_0 * (h_0 / h[j])^2)\n",
    "# Time of flight\n",
    "@NLexpression(rocket, t_f, Δt * n)\n",
    "\n",
    "# Dynamics\n",
    "for j in 2:n\n",
    "    # h' = v\n",
    "    \n",
    "    # Rectangular integration\n",
    "    # @NLconstraint(rocket, h[j] == h[j - 1] + Δt * v[j - 1])\n",
    "    \n",
    "    # Trapezoidal integration\n",
    "    @NLconstraint(rocket,\n",
    "        h[j] == h[j - 1] + 0.5 * Δt * (v[j] + v[j - 1]))\n",
    "\n",
    "    # v' = (T-D(h,v))/m - g(h)\n",
    "    \n",
    "    # Rectangular integration\n",
    "    # @NLconstraint(rocket, v[j] == v[j - 1] + Δt *(\n",
    "    #                 (T[j - 1] - drag[j - 1]) / m[j - 1] - grav[j - 1]))\n",
    "    \n",
    "    # Trapezoidal integration\n",
    "    @NLconstraint(rocket,\n",
    "        v[j] == v[j-1] + 0.5 * Δt * (\n",
    "            (T[j] - drag[j] - m[j] * grav[j]) / m[j] +\n",
    "            (T[j - 1] - drag[j - 1] - m[j - 1] * grav[j - 1]) / m[j - 1]))\n",
    "\n",
    "    # m' = -T/c\n",
    "\n",
    "    # Rectangular integration\n",
    "    # @NLconstraint(rocket, m[j] == m[j - 1] - Δt * T[j - 1] / c)\n",
    "    \n",
    "    # Trapezoidal integration\n",
    "    @NLconstraint(rocket,\n",
    "        m[j] == m[j - 1] - 0.5 * Δt * (T[j] + T[j-1]) / c)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for the control and state\n",
    "println(\"Solving...\")\n",
    "status = optimize!(rocket)\n",
    "\n",
    "# Display results\n",
    "# println(\"Solver status: \", status)\n",
    "println(\"Max height: \", objective_value(rocket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.(h)[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can visualize the state and control variables\n",
    "using Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_plot = plot(x = (1:n) * value.(Δt), y = value.(h)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Altitude\"))\n",
    "m_plot = plot(x = (1:n) * value.(Δt), y = value.(m)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Mass\"))\n",
    "v_plot = plot(x = (1:n) * value.(Δt), y = value.(v)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Velocity\"))\n",
    "T_plot = plot(x = (1:n) * value.(Δt), y = value.(T)[:], Geom.line,\n",
    "                Guide.xlabel(\"Time (s)\"), Guide.ylabel(\"Thrust\"))\n",
    "draw(SVG(6inch, 6inch), vstack(hstack(h_plot, m_plot), hstack(v_plot, T_plot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:     \n",
    "    - i) Transformer le modèle JuMP utilisé ci-dessus en un NLPModel en utilisant le package `NLPModelsJuMP`.    \n",
    "    - ii) Résoudre ce nouveau modèle avec `Ipopt` en utilisant `NLPModelsIpopt`.    \n",
    "    - iii) Calcul séparément la différence entre les h,v,m,T, Δt calculés.    \n",
    "    - iv) Est-ce que le contrôle T atteint ses bornes ?    \n",
    "    - v) Reproduire les graphiques ci-dessous avec la solution calculée via `NLPModelsIpopt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NLPModels, LinearAlgebra, NLPModelsJuMP, NLPModelsIpopt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
